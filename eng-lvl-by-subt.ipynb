{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting the English level of a movie by it's subtitles\n",
    "\n",
    "### Research goals \n",
    "- Practising on a real textual data\n",
    "- Discover basics of the NLP\n",
    "- Sharpen building prediction models skill\n",
    "\n",
    "### Research progress\n",
    "- Data acquisition and initial analysis\n",
    "- Check for duplicates and gaps, correct where it's possible\n",
    "- Check data for anomalies\n",
    "- Correlation analysis\n",
    "- Data preprocessing and cleaning\n",
    "- Train and asses models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition and initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/artem.pochechuev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/artem.pochechuev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/artem.pochechuev/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet  as cdt\n",
    "import os\n",
    "import pysrt\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "RANDOM_VAL = 12345\n",
    "subs_path = './data/Subtitles_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ability</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>able</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abortion</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>yours</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>yourself</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>youth</td>\n",
       "      <td>b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>zero</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>zone</td>\n",
       "      <td>b2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word level\n",
       "0      abandon    b2\n",
       "1      ability    a2\n",
       "2         able    a2\n",
       "3      abolish    c1\n",
       "4     abortion    c1\n",
       "...        ...   ...\n",
       "5328     yours    a2\n",
       "5329  yourself    a1\n",
       "5330     youth    b1\n",
       "5331      zero    a2\n",
       "5332      zone    b2\n",
       "\n",
       "[5297 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2    1425\n",
      "c1    1312\n",
      "a1     891\n",
      "a2     865\n",
      "b1     804\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_dict = pd.read_csv('data/oxford_cefr.csv', encoding = \"latin\")\n",
    "df_dict = df_dict.drop_duplicates()\n",
    "display(df_dict)\n",
    "print(df_dict['level'].value_counts())\n",
    "df_dict = dict(df_dict.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Matilda(2022)</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Bullet train</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Thor: love and thunder</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Lightyear</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>The Grinch</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                movie   level\n",
       "0           10_Cloverfield_lane(2016)      B1\n",
       "1    10_things_I_hate_about_you(1999)      B1\n",
       "2                A_knights_tale(2001)      B2\n",
       "3                A_star_is_born(2018)      B2\n",
       "4                       Aladdin(1992)  A2/A2+\n",
       "..                                ...     ...\n",
       "236                     Matilda(2022)      C1\n",
       "237                      Bullet train      B1\n",
       "238            Thor: love and thunder      B2\n",
       "239                         Lightyear      B2\n",
       "240                        The Grinch      B1\n",
       "\n",
       "[241 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2            101\n",
      "B1             55\n",
      "C1             40\n",
      "A2/A2+         26\n",
      "B1, B2          8\n",
      "A2              6\n",
      "A2/A2+, B1      5\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/movies_labels.xlsx')\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df = df.rename(columns=str.lower)\n",
    "display(df)\n",
    "print(df['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/Subtitles/10_Cloverfield_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/Subtitles/10_things_I_hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>./data/Subtitles_all/Subtitles/A_knights_tale(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>./data/Subtitles_all/Subtitles/A_star_is_born(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>./data/Subtitles_all/Subtitles/Aladdin(1992).srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Indiana Jones And The Last Crusade DVDRip Xvid...</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/B1/Indiana Jones And The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Seven.Worlds.One.Planet.S01E04.2160p.BluRay.Re...</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/B1/Seven.Worlds.One.Plane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Seven.Worlds.One.Planet.S01E03.2160p.BluRay.Re...</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/B1/Seven.Worlds.One.Plane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Angelas.Christmas.Wish.2020.srt</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/B1/Angelas.Christmas.Wish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Terminator_2_Judgment_Day_1991_roNy.srt</td>\n",
       "      <td>B1</td>\n",
       "      <td>./data/Subtitles_all/B1/Terminator_2_Judgment_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 movie   level  \\\n",
       "0                            10_Cloverfield_lane(2016)      B1   \n",
       "1                     10_things_I_hate_about_you(1999)      B1   \n",
       "2                                 A_knights_tale(2001)      B2   \n",
       "3                                 A_star_is_born(2018)      B2   \n",
       "4                                        Aladdin(1992)  A2/A2+   \n",
       "..                                                 ...     ...   \n",
       "399  Indiana Jones And The Last Crusade DVDRip Xvid...      B1   \n",
       "400  Seven.Worlds.One.Planet.S01E04.2160p.BluRay.Re...      B1   \n",
       "401  Seven.Worlds.One.Planet.S01E03.2160p.BluRay.Re...      B1   \n",
       "402                    Angelas.Christmas.Wish.2020.srt      B1   \n",
       "403            Terminator_2_Judgment_Day_1991_roNy.srt      B1   \n",
       "\n",
       "                                                  path  \n",
       "0    ./data/Subtitles_all/Subtitles/10_Cloverfield_...  \n",
       "1    ./data/Subtitles_all/Subtitles/10_things_I_hat...  \n",
       "2    ./data/Subtitles_all/Subtitles/A_knights_tale(...  \n",
       "3    ./data/Subtitles_all/Subtitles/A_star_is_born(...  \n",
       "4     ./data/Subtitles_all/Subtitles/Aladdin(1992).srt  \n",
       "..                                                 ...  \n",
       "399  ./data/Subtitles_all/B1/Indiana Jones And The ...  \n",
       "400  ./data/Subtitles_all/B1/Seven.Worlds.One.Plane...  \n",
       "401  ./data/Subtitles_all/B1/Seven.Worlds.One.Plane...  \n",
       "402  ./data/Subtitles_all/B1/Angelas.Christmas.Wish...  \n",
       "403  ./data/Subtitles_all/B1/Terminator_2_Judgment_...  \n",
       "\n",
       "[404 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['path'] = subs_path + '/Subtitles/' + df['movie'] + '.srt'\n",
    "\n",
    "for dir in os.listdir(subs_path):\n",
    "    if not dir.__contains__('.DS_Store') and not dir.__contains__('Subtitles'):\n",
    "        movies_arr = os.listdir(subs_path+'/'+dir)\n",
    "        rows = pd.DataFrame({'movie' : movies_arr, 'level': np.full(len(movies_arr), dir), 'path': [f\"{subs_path}/{dir}/{mvi}\" for mvi in movies_arr]})\n",
    "        df = pd.concat([df, rows], ignore_index = True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B2    216\n",
       "B1     75\n",
       "C1     73\n",
       "A2     38\n",
       "Name: level, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.loc[df['level'] == 'A2/A2+', 'level'] = 'A2'\n",
    "df.loc[df['level'] == 'B1, B2', 'level'] = 'B2'\n",
    "df.loc[df['level'] == 'A2/A2+, B1', 'level'] = 'B1'\n",
    "\n",
    "display(df['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_text(file_path):\n",
    "    result_words = []\n",
    "\n",
    "    with open(file_path, 'rb') as sub_file:\n",
    "        file_content = sub_file.read()\n",
    "\n",
    "    encoding = cdt.detect(file_content).get('encoding')\n",
    "\n",
    "    subs = pysrt.open(file_path, encoding)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for sub in subs:\n",
    "        result_text = BeautifulSoup(sub.text.lower(), \"lxml\").text\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = word_tokenize(result_text)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        result_words.extend([lemmatizer.lemmatize(word) for word in words])\n",
    "\n",
    "    return result_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_data(file_path, level, name, columns):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise Exception(\"Subtitile does not exist\")\n",
    "\n",
    "    res_stat = dict.fromkeys(columns, 0)\n",
    "    res_stat['name'] = name\n",
    "    res_stat['level'] = level\n",
    "    \n",
    "    result_words = proc_text(file_path)\n",
    "\n",
    "    for word in result_words:\n",
    "        if word not in df_dict:\n",
    "            res_stat['unknown'] += 1\n",
    "        else:\n",
    "            res_stat[df_dict.get(word)] += 1\n",
    "\n",
    "    res_stat['text'] = ' '.join(result_words)\n",
    "\n",
    "    if(os.path.exists('dump.txt')):\n",
    "        os.remove('dump.txt')\n",
    "\n",
    "    with open('dump.txt', 'a') as f:\n",
    "       f.write(f'subtitles from: {file_path}\\n')\n",
    "       f.write(res_stat['text'])\n",
    "       f.write('\\n\\n')\n",
    "\n",
    "    return res_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/2sc430n96dj6kjy96ql5m9m00000gn/T/ipykernel_2472/945480646.py:13: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  result_text = BeautifulSoup(sub.text.lower(), \"lxml\").text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>a2</th>\n",
       "      <th>c1</th>\n",
       "      <th>a1</th>\n",
       "      <th>unknown</th>\n",
       "      <th>text</th>\n",
       "      <th>encoding</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229</td>\n",
       "      <td>185</td>\n",
       "      <td>295</td>\n",
       "      <td>75</td>\n",
       "      <td>802</td>\n",
       "      <td>1038</td>\n",
       "      <td>fixed synced bozxphd enjoy flick clanging draw...</td>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348</td>\n",
       "      <td>283</td>\n",
       "      <td>444</td>\n",
       "      <td>126</td>\n",
       "      <td>1378</td>\n",
       "      <td>1082</td>\n",
       "      <td>hey right cameron go nine school year army bra...</td>\n",
       "      <td>0</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>327</td>\n",
       "      <td>465</td>\n",
       "      <td>162</td>\n",
       "      <td>1069</td>\n",
       "      <td>1121</td>\n",
       "      <td>resync xenzai nef retail help due list two min...</td>\n",
       "      <td>0</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>430</td>\n",
       "      <td>696</td>\n",
       "      <td>162</td>\n",
       "      <td>2542</td>\n",
       "      <td>1597</td>\n",
       "      <td>synced corrected mrcjnthn get black eye open w...</td>\n",
       "      <td>0</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>474</td>\n",
       "      <td>376</td>\n",
       "      <td>598</td>\n",
       "      <td>147</td>\n",
       "      <td>1196</td>\n",
       "      <td>1469</td>\n",
       "      <td>oh come land faraway place caravan camel roam ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>232</td>\n",
       "      <td>311</td>\n",
       "      <td>424</td>\n",
       "      <td>103</td>\n",
       "      <td>1117</td>\n",
       "      <td>1234</td>\n",
       "      <td>dismount herman chap one wander passageway run...</td>\n",
       "      <td>0</td>\n",
       "      <td>Indiana Jones And The Last Crusade DVDRip Xvid...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>153</td>\n",
       "      <td>136</td>\n",
       "      <td>211</td>\n",
       "      <td>64</td>\n",
       "      <td>398</td>\n",
       "      <td>407</td>\n",
       "      <td>australia island continent cast adrift time di...</td>\n",
       "      <td>0</td>\n",
       "      <td>Seven.Worlds.One.Planet.S01E04.2160p.BluRay.Re...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>155</td>\n",
       "      <td>132</td>\n",
       "      <td>212</td>\n",
       "      <td>47</td>\n",
       "      <td>340</td>\n",
       "      <td>305</td>\n",
       "      <td>southern tip south america andes mountain rise...</td>\n",
       "      <td>0</td>\n",
       "      <td>Seven.Worlds.One.Planet.S01E03.2160p.BluRay.Re...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>92</td>\n",
       "      <td>76</td>\n",
       "      <td>202</td>\n",
       "      <td>20</td>\n",
       "      <td>563</td>\n",
       "      <td>427</td>\n",
       "      <td>going come angela mind sheep dada want hear so...</td>\n",
       "      <td>0</td>\n",
       "      <td>Angelas.Christmas.Wish.2020.srt</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>279</td>\n",
       "      <td>289</td>\n",
       "      <td>385</td>\n",
       "      <td>60</td>\n",
       "      <td>1003</td>\n",
       "      <td>761</td>\n",
       "      <td>billion human life ended august survivor nucle...</td>\n",
       "      <td>0</td>\n",
       "      <td>Terminator_2_Judgment_Day_1991_roNy.srt</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      b1   b2   a2   c1    a1  unknown  \\\n",
       "0    229  185  295   75   802     1038   \n",
       "1    348  283  444  126  1378     1082   \n",
       "2    304  327  465  162  1069     1121   \n",
       "3    449  430  696  162  2542     1597   \n",
       "4    474  376  598  147  1196     1469   \n",
       "..   ...  ...  ...  ...   ...      ...   \n",
       "266  232  311  424  103  1117     1234   \n",
       "267  153  136  211   64   398      407   \n",
       "268  155  132  212   47   340      305   \n",
       "269   92   76  202   20   563      427   \n",
       "270  279  289  385   60  1003      761   \n",
       "\n",
       "                                                  text  encoding  \\\n",
       "0    fixed synced bozxphd enjoy flick clanging draw...         0   \n",
       "1    hey right cameron go nine school year army bra...         0   \n",
       "2    resync xenzai nef retail help due list two min...         0   \n",
       "3    synced corrected mrcjnthn get black eye open w...         0   \n",
       "4    oh come land faraway place caravan camel roam ...         0   \n",
       "..                                                 ...       ...   \n",
       "266  dismount herman chap one wander passageway run...         0   \n",
       "267  australia island continent cast adrift time di...         0   \n",
       "268  southern tip south america andes mountain rise...         0   \n",
       "269  going come angela mind sheep dada want hear so...         0   \n",
       "270  billion human life ended august survivor nucle...         0   \n",
       "\n",
       "                                                  name level  \n",
       "0                            10_Cloverfield_lane(2016)    B1  \n",
       "1                     10_things_I_hate_about_you(1999)    B1  \n",
       "2                                 A_knights_tale(2001)    B2  \n",
       "3                                 A_star_is_born(2018)    B2  \n",
       "4                                        Aladdin(1992)    A2  \n",
       "..                                                 ...   ...  \n",
       "266  Indiana Jones And The Last Crusade DVDRip Xvid...    B1  \n",
       "267  Seven.Worlds.One.Planet.S01E04.2160p.BluRay.Re...    B1  \n",
       "268  Seven.Worlds.One.Planet.S01E03.2160p.BluRay.Re...    B1  \n",
       "269                    Angelas.Christmas.Wish.2020.srt    B1  \n",
       "270            Terminator_2_Judgment_Day_1991_roNy.srt    B1  \n",
       "\n",
       "[271 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = list(set(df_dict.values()))\n",
    "columns.extend(['unknown', 'text', 'encoding', 'name'])\n",
    "\n",
    "rows_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if os.path.exists(row['path']):\n",
    "        rows_list.append(get_sub_data(df.at[idx, 'path'], df.at[idx, 'level'], df.at[idx, 'movie'], columns=columns))\n",
    "\n",
    "rows_res_df = pd.DataFrame(rows_list)\n",
    "display(rows_res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2train = [\n",
    "    LinearSVC(max_iter=3000, random_state=RANDOM_VAL),\n",
    "    CatBoostClassifier(random_state=RANDOM_VAL, silent=True),\n",
    "    RandomForestClassifier(n_estimators=15, random_state=RANDOM_VAL),\n",
    "    LogisticRegression(random_state=RANDOM_VAL, solver='lbfgs', max_iter=10000),\n",
    "    RidgeClassifier(random_state=RANDOM_VAL, max_iter=10000),\n",
    "    SGDClassifier(random_state=RANDOM_VAL, max_iter=10000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(header, ppln, X_train, X_test, Y_train, Y_test):\n",
    "    ppln.fit(X_train, Y_train)\n",
    "    predicted = ppln.predict(X_test)\n",
    "    \n",
    "    print(f'{header} results:')    \n",
    "    print('confusion_matrix:\\n', confusion_matrix(Y_test, predicted))\n",
    "    print('classification_report:\\n', classification_report(Y_test, predicted))\n",
    "    print('accuracy_score:', accuracy_score(Y_test, predicted))\n",
    "    print('f1_score_macro:', f1_score(Y_test, predicted, average='macro'), 'f1_score_micro:', f1_score(Y_test, predicted, average='micro'))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 - predicting CEFR level by number of leveled words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_leveled = rows_res_df.drop(['level', 'text', 'encoding', 'name'], axis=1)\n",
    "target = rows_res_df['level']\n",
    "\n",
    "features_train_lvl, features_test_lvl, target_train_lvl, target_test_lvl = train_test_split(features_leveled, target, train_size=0.2, random_state=RANDOM_VAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== CEFR level by number of leveled words in text ===========\n",
      "LinearSVC results:\n",
      "confusion_matrix:\n",
      " [[ 2 12 11  0]\n",
      " [ 4 20 16  0]\n",
      " [ 8 28 85  0]\n",
      " [ 1  5 25  0]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.13      0.08      0.10        25\n",
      "          B1       0.31      0.50      0.38        40\n",
      "          B2       0.62      0.70      0.66       121\n",
      "          C1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.49       217\n",
      "   macro avg       0.27      0.32      0.28       217\n",
      "weighted avg       0.42      0.49      0.45       217\n",
      "\n",
      "accuracy_score: 0.4930875576036866\n",
      "f1_score_macro: 0.28496677740863785 f1_score_micro: 0.4930875576036866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier results:\n",
      "confusion_matrix:\n",
      " [[ 1 16  6  2]\n",
      " [ 4 18 17  1]\n",
      " [ 2 32 68 19]\n",
      " [ 2  1 16 12]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.11      0.04      0.06        25\n",
      "          B1       0.27      0.45      0.34        40\n",
      "          B2       0.64      0.56      0.60       121\n",
      "          C1       0.35      0.39      0.37        31\n",
      "\n",
      "    accuracy                           0.46       217\n",
      "   macro avg       0.34      0.36      0.34       217\n",
      "weighted avg       0.47      0.46      0.45       217\n",
      "\n",
      "accuracy_score: 0.45622119815668205\n",
      "f1_score_macro: 0.3402485312108876 f1_score_micro: 0.45622119815668205\n",
      "\n",
      "RandomForestClassifier results:\n",
      "confusion_matrix:\n",
      " [[ 5 11  8  1]\n",
      " [ 5 16 18  1]\n",
      " [ 5 30 64 22]\n",
      " [ 2  2 15 12]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.29      0.20      0.24        25\n",
      "          B1       0.27      0.40      0.32        40\n",
      "          B2       0.61      0.53      0.57       121\n",
      "          C1       0.33      0.39      0.36        31\n",
      "\n",
      "    accuracy                           0.45       217\n",
      "   macro avg       0.38      0.38      0.37       217\n",
      "weighted avg       0.47      0.45      0.45       217\n",
      "\n",
      "accuracy_score: 0.4470046082949309\n",
      "f1_score_macro: 0.3714770494918428 f1_score_micro: 0.4470046082949309\n",
      "\n",
      "LogisticRegression results:\n",
      "confusion_matrix:\n",
      " [[ 0 11 14  0]\n",
      " [ 3 19 18  0]\n",
      " [ 3 24 94  0]\n",
      " [ 0  6 25  0]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.00      0.00      0.00        25\n",
      "          B1       0.32      0.47      0.38        40\n",
      "          B2       0.62      0.78      0.69       121\n",
      "          C1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.52       217\n",
      "   macro avg       0.23      0.31      0.27       217\n",
      "weighted avg       0.41      0.52      0.46       217\n",
      "\n",
      "accuracy_score: 0.5207373271889401\n",
      "f1_score_macro: 0.2677941176470588 f1_score_micro: 0.5207373271889401\n",
      "\n",
      "RidgeClassifier results:\n",
      "confusion_matrix:\n",
      " [[ 2 10 13  0]\n",
      " [ 4 20 16  0]\n",
      " [ 6 26 89  0]\n",
      " [ 1  5 25  0]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.15      0.08      0.11        25\n",
      "          B1       0.33      0.50      0.40        40\n",
      "          B2       0.62      0.74      0.67       121\n",
      "          C1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.51       217\n",
      "   macro avg       0.28      0.33      0.29       217\n",
      "weighted avg       0.43      0.51      0.46       217\n",
      "\n",
      "accuracy_score: 0.511520737327189\n",
      "f1_score_macro: 0.29388629652438925 f1_score_micro: 0.511520737327189\n",
      "\n",
      "SGDClassifier results:\n",
      "confusion_matrix:\n",
      " [[ 3  8  6  8]\n",
      " [ 6 23  6  5]\n",
      " [12 29 39 41]\n",
      " [ 1  2 12 16]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.14      0.12      0.13        25\n",
      "          B1       0.37      0.57      0.45        40\n",
      "          B2       0.62      0.32      0.42       121\n",
      "          C1       0.23      0.52      0.32        31\n",
      "\n",
      "    accuracy                           0.37       217\n",
      "   macro avg       0.34      0.38      0.33       217\n",
      "weighted avg       0.46      0.37      0.38       217\n",
      "\n",
      "accuracy_score: 0.37327188940092165\n",
      "f1_score_macro: 0.3298461733178814 f1_score_micro: 0.37327188940092165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train_lvl)\n",
    "\n",
    "features_train_lvl = scaler.transform(features_train_lvl)\n",
    "features_test_lvl = scaler.transform(features_test_lvl)\n",
    "print(\"=========== CEFR level by number of leveled words in text ===========\")\n",
    "\n",
    "for model in models2train:\n",
    "    print_metrics(type(model).__name__, model, features_train_lvl, features_test_lvl, target_train_lvl, target_test_lvl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 - predicting CEFR level by text embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(rows_res_df['text'], target, train_size=0.2, random_state=RANDOM_VAL, stratify=target)\n",
    "vectorizer = TfidfVectorizer(max_features=1500, min_df=4, max_df=0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC results:\n",
      "confusion_matrix:\n",
      " [[ 4 12  9  0]\n",
      " [ 3 21 20  2]\n",
      " [ 7 12 94  2]\n",
      " [ 0  1 26  4]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.29      0.16      0.21        25\n",
      "          B1       0.46      0.46      0.46        46\n",
      "          B2       0.63      0.82      0.71       115\n",
      "          C1       0.50      0.13      0.21        31\n",
      "\n",
      "    accuracy                           0.57       217\n",
      "   macro avg       0.47      0.39      0.39       217\n",
      "weighted avg       0.54      0.57      0.53       217\n",
      "\n",
      "accuracy_score: 0.5668202764976958\n",
      "f1_score_macro: 0.3947248403770143 f1_score_micro: 0.5668202764976958\n",
      "\n",
      "CatBoostClassifier results:\n",
      "confusion_matrix:\n",
      " [[  0   2  23   0]\n",
      " [  0  13  33   0]\n",
      " [  1   5 109   0]\n",
      " [  0   1  30   0]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.00      0.00      0.00        25\n",
      "          B1       0.62      0.28      0.39        46\n",
      "          B2       0.56      0.95      0.70       115\n",
      "          C1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.56       217\n",
      "   macro avg       0.29      0.31      0.27       217\n",
      "weighted avg       0.43      0.56      0.45       217\n",
      "\n",
      "accuracy_score: 0.5622119815668203\n",
      "f1_score_macro: 0.2728213769860376 f1_score_micro: 0.5622119815668203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier results:\n",
      "confusion_matrix:\n",
      " [[  0   5  20   0]\n",
      " [  2  15  29   0]\n",
      " [  2   5 107   1]\n",
      " [  0   0  27   4]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.00      0.00      0.00        25\n",
      "          B1       0.60      0.33      0.42        46\n",
      "          B2       0.58      0.93      0.72       115\n",
      "          C1       0.80      0.13      0.22        31\n",
      "\n",
      "    accuracy                           0.58       217\n",
      "   macro avg       0.50      0.35      0.34       217\n",
      "weighted avg       0.55      0.58      0.50       217\n",
      "\n",
      "accuracy_score: 0.5806451612903226\n",
      "f1_score_macro: 0.3407195597147389 f1_score_micro: 0.5806451612903226\n",
      "\n",
      "LogisticRegression results:\n",
      "confusion_matrix:\n",
      " [[  0   0  25   0]\n",
      " [  0   2  44   0]\n",
      " [  0   1 114   0]\n",
      " [  0   0  28   3]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.00      0.00      0.00        25\n",
      "          B1       0.67      0.04      0.08        46\n",
      "          B2       0.54      0.99      0.70       115\n",
      "          C1       1.00      0.10      0.18        31\n",
      "\n",
      "    accuracy                           0.55       217\n",
      "   macro avg       0.55      0.28      0.24       217\n",
      "weighted avg       0.57      0.55      0.41       217\n",
      "\n",
      "accuracy_score: 0.5483870967741935\n",
      "f1_score_macro: 0.2393724360910008 f1_score_micro: 0.5483870967741935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier results:\n",
      "confusion_matrix:\n",
      " [[  3   7  15   0]\n",
      " [  3  15  28   0]\n",
      " [  3   8 104   0]\n",
      " [  0   1  26   4]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.33      0.12      0.18        25\n",
      "          B1       0.48      0.33      0.39        46\n",
      "          B2       0.60      0.90      0.72       115\n",
      "          C1       1.00      0.13      0.23        31\n",
      "\n",
      "    accuracy                           0.58       217\n",
      "   macro avg       0.60      0.37      0.38       217\n",
      "weighted avg       0.60      0.58      0.52       217\n",
      "\n",
      "accuracy_score: 0.5806451612903226\n",
      "f1_score_macro: 0.37921865715983366 f1_score_micro: 0.5806451612903226\n",
      "\n",
      "SGDClassifier results:\n",
      "confusion_matrix:\n",
      " [[ 4 11  9  1]\n",
      " [ 2 30 11  3]\n",
      " [ 2 18 86  9]\n",
      " [ 0  1 23  7]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.50      0.16      0.24        25\n",
      "          B1       0.50      0.65      0.57        46\n",
      "          B2       0.67      0.75      0.70       115\n",
      "          C1       0.35      0.23      0.27        31\n",
      "\n",
      "    accuracy                           0.59       217\n",
      "   macro avg       0.50      0.45      0.45       217\n",
      "weighted avg       0.57      0.59      0.56       217\n",
      "\n",
      "accuracy_score: 0.5852534562211982\n",
      "f1_score_macro: 0.4469724537454382 f1_score_micro: 0.5852534562211982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models2train:\n",
    "    ppln = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    print_metrics(type(model).__name__, ppln, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppln = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('model', SGDClassifier(random_state=RANDOM_VAL, max_iter=10000))\n",
    "])\n",
    "\n",
    "ppln.fit(X_train, Y_train)\n",
    "\n",
    "with open('models/sgd_model.pcl', 'wb') as f:\n",
    "    pickle.dump(ppln, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: C1 real level: B1 name: 10_Cloverfield_lane(2016)\n",
      "predicted: B1 real level: B1 name: 10_things_I_hate_about_you(1999)\n",
      "predicted: B2 real level: B2 name: A_knights_tale(2001)\n",
      "predicted: B1 real level: B2 name: A_star_is_born(2018)\n",
      "predicted: B1 real level: A2 name: Aladdin(1992)\n",
      "predicted: B2 real level: A2 name: All_dogs_go_to_heaven(1989)\n",
      "predicted: B1 real level: A2 name: An_American_tail(1986)\n",
      "predicted: A2 real level: A2 name: Babe(1995)\n",
      "predicted: B2 real level: A2 name: Back_to_the_future(1985)\n",
      "predicted: B2 real level: C1 name: Banking_On_Bitcoin(2016)\n",
      "predicted: B2 real level: A2 name: Batman_begins(2005)\n",
      "predicted: B2 real level: B2 name: Beauty_and_the_beast(2017)\n",
      "predicted: B2 real level: B2 name: Before_I_go_to_sleep(2014)\n",
      "predicted: B1 real level: B2 name: Before_sunrise(1995)\n",
      "predicted: B1 real level: B2 name: Before_sunset(2004)\n",
      "predicted: B2 real level: B2 name: Braveheart(1995)\n",
      "predicted: C1 real level: B2 name: Bridget_Jones_diary(2001)\n",
      "predicted: C1 real level: C1 name: Bridget_Joness_Baby\n",
      "predicted: B1 real level: B1 name: Cars(2006)\n",
      "predicted: B1 real level: A2 name: Cast_away(2000)\n",
      "predicted: B1 real level: B2 name: Catch_me_if_you_can(2002)\n",
      "predicted: B1 real level: B1 name: Charlie_and_the_Chocolate_Factory\n",
      "predicted: B1 real level: B1 name: Cinderella(1950)\n",
      "predicted: B1 real level: B1 name: Clueless(1995)\n",
      "predicted: C1 real level: B2 name: Deadpool(2016)\n",
      "predicted: B1 real level: B2 name: Despicable_Me(2010)\n",
      "predicted: B1 real level: B1 name: Die_hard(1988)\n",
      "predicted: B1 real level: A2 name: Dredd(2012)\n",
      "predicted: B2 real level: B2 name: Dune(2021)\n",
      "predicted: B2 real level: B2 name: Enola_Holmes(2020)\n",
      "predicted: B1 real level: B2 name: Entrapment\n",
      "predicted: A2 real level: A2 name: Eurovision_song_contest_(2020)\n",
      "predicted: A2 real level: B1 name: Ferdinand(2017)\n",
      "predicted: B1 real level: B2 name: Fight_club(1999)\n",
      "predicted: B1 real level: A2 name: Finding_Nemo(2003)\n",
      "predicted: B2 real level: B1 name: Forrest_Gump(1994)\n",
      "predicted: B1 real level: B2 name: Good_Will_Hunting(1997)\n",
      "predicted: B2 real level: B1 name: Groundhog_day(1993)\n",
      "predicted: B1 real level: B1 name: Powder(1995)\n",
      "predicted: B1 real level: B1 name: Her(2013)\n",
      "predicted: B1 real level: B1 name: Home_alone(1990)\n",
      "predicted: B1 real level: A2 name: Hook(1991)\n",
      "predicted: B1 real level: B2 name: House_of_Gucci(2021)\n",
      "predicted: A2 real level: B1 name: Inside_out(2015)\n",
      "predicted: C1 real level: A2 name: Its_a_wonderful_life(1946)\n",
      "predicted: B2 real level: C1 name: Klaus(2019)\n",
      "predicted: B1 real level: B2 name: Knives_out(2019)\n",
      "predicted: A2 real level: A2 name: Kubo_and_the_two_strings(2016)\n",
      "predicted: B1 real level: B1 name: Liar_liar(1997)\n",
      "predicted: C1 real level: B2 name: Lion(2016)\n",
      "predicted: C1 real level: B1 name: Logan(2017)\n",
      "predicted: B1 real level: B1 name: Love_actually(2003)\n",
      "predicted: B2 real level: B2 name: Made_of_Honor(2008)\n",
      "predicted: B2 real level: B1 name: Mamma_Mia(2008)\n",
      "predicted: B1 real level: B1 name: Mary_Poppins_returns(2018)\n",
      "predicted: B1 real level: B1 name: Matilda(1996)\n",
      "predicted: B1 real level: B1 name: Meet_the_parents(2000)\n",
      "predicted: B2 real level: B1 name: Milada(2017)\n",
      "predicted: B2 real level: B2 name: Mona_Lisa_Smile(2003)\n",
      "predicted: B2 real level: B1 name: Moulin_Rouge(2001)\n",
      "predicted: B1 real level: B1 name: Mrs_Doubtfire(1993)\n",
      "predicted: B2 real level: A2 name: My_big_fat_Greek_wedding(2002)\n",
      "predicted: C1 real level: B1 name: Notting_Hill(1999)\n",
      "predicted: B1 real level: C1 name: Oceans_Eleven(2001)\n",
      "predicted: B2 real level: C1 name: Oceans_Twelve(2004)\n",
      "predicted: B2 real level: B1 name: Pirates_of_the_Caribbean(2003)\n",
      "predicted: B1 real level: B1 name: Pleasantville(1998)\n",
      "predicted: B1 real level: B2 name: Pulp_fiction(1994)\n",
      "predicted: B1 real level: B2 name: Ratatouille(2007)\n",
      "predicted: B1 real level: A2 name: Ready_or_not(2019)\n",
      "predicted: B2 real level: B1 name: Shrek(2001)\n",
      "predicted: A2 real level: A2 name: Sleepless_in_Seattle(1993)\n",
      "predicted: B1 real level: B1 name: Soul(2020)\n",
      "predicted: B1 real level: B2 name: The_blind_side(2009)\n",
      "predicted: B1 real level: B2 name: The_Devil_Wears_Prad\n",
      "predicted: B1 real level: B1 name: The_Fundamentals_of_Caring(2016)\n",
      "predicted: B2 real level: A2 name: The_greatest_showman(2017)\n",
      "predicted: B1 real level: B2 name: The_Intern(2015)\n",
      "predicted: C1 real level: C1 name: The_Legend_of_Tarzan(2016)\n",
      "predicted: B2 real level: B2 name: The_Shawshank_redemption(1994)\n",
      "predicted: B1 real level: B1 name: The_terminal(2004)\n",
      "predicted: B1 real level: B1 name: The_blind_side(2009)\n",
      "predicted: B1 real level: A2 name: The_break-up(2006)\n",
      "predicted: A2 real level: A2 name: The_cabin_in_the_woods(2012)\n",
      "predicted: B1 real level: B1 name: The_fault_in_our_stars(2014)\n",
      "predicted: C1 real level: B2 name: The_graduate(1967)\n",
      "predicted: B1 real level: B2 name: The_hangover(2009)\n",
      "predicted: B1 real level: B1 name: The_holiday(2006)\n",
      "predicted: B2 real level: A2 name: The_invisible_man(2020)\n",
      "predicted: A2 real level: A2 name: The_jungle_book(2016)\n",
      "predicted: B2 real level: B2 name: The_kings_speech(2010)\n",
      "predicted: B2 real level: A2 name: The_lion_king(1994)\n",
      "predicted: B2 real level: B2 name: The_lord_of_the_rings(2001)\n",
      "predicted: B1 real level: A2 name: The_man_called_Flintstone(1966)\n",
      "predicted: B1 real level: B1 name: The_secret_life_of_Walter_Mitty(2013)\n",
      "predicted: C1 real level: B2 name: The_social_network(2010)\n",
      "predicted: B1 real level: B1 name: The_terminal(2004)\n",
      "predicted: B1 real level: B1 name: The_terminator(1984)\n",
      "predicted: C1 real level: B2 name: The_theory_of_everything(2014)\n",
      "predicted: B2 real level: B2 name: The_usual_suspects(1995)\n",
      "predicted: B2 real level: B2 name: Titanic(1997)\n",
      "predicted: B1 real level: A2 name: Toy_story(1995)\n",
      "predicted: B1 real level: A2 name: Twilight(2008)\n",
      "predicted: B1 real level: B2 name: Venom(2018)\n",
      "predicted: B1 real level: B1 name: Warm_bodies(2013)\n",
      "predicted: B1 real level: B1 name: We_are_the_Millers(2013)\n",
      "predicted: B1 real level: B1 name: While_You_Were_Sleeping(1995)\n",
      "predicted: B2 real level: B2 name: Zootopia(2016)\n",
      "predicted: B2 real level: B2 name: Crown, The S01E01 - Wolferton Splash.en.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 1- Denial.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E06.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E08.HDTV.x264-EVOLVE.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E04.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E09.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E14.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E14.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E04 - Act of God.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E09.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E05 - Smoke and Mirrors.en.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E03 - Windsor.en.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 11- Blowback.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E12.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Collateral.Beauty.2016.720p.BRRip.x264.AAC-ETRG.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E05 - Smoke and Mirrors.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Roman Holiday 1953 1080p WEBRip HEVC AAC.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 3- No Refills.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E05.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E13.REPACK.HDTV.x264-2HD.srt\n",
      "predicted: B2 real level: B2 name: icarus.2017.web.x264-strife.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E04 - Act of God.en.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 16- 25th Hour.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E10 - Gloriana.en.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E08.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 4- No Puedo Hacerlo.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 14- Self Defense.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E07 - Scientia Potentia Est.en.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E05.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E09 - Assassins.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E11.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E06.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E07.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 13- God's Green Earth.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E06.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E15.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: A2 real level: B2 name: Angela's.Christmas.2018.WEBRip.Netflix.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E02.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E13.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E04.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E12.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E10 - Gloriana.en.FORCED.srt\n",
      "predicted: B2 real level: B2 name: Secrets Of Her Majesty's Secret Service eng.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E01.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 8- Mea Culpa.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E09.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E02 - Hyde Park Corner.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E06.All.In.HDTV.x264-FQM.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E07.Sucker.Punch.PROPER.HDTV.x264-FQM.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E10.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E03.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E02 - Hyde Park Corner.en.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E02.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E03.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E07 - Scientia Potentia Est.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E11.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 5- Toe to Toe.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 12- Live to Fight.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E03 - Windsor.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E01.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: z srt23 uk-bun Gullivers.Travels.1939.720p.BluRay.x264-CiNEFiLE.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E04.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E12.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E16.HDTV.x264-2HD.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E09 - Assassins.en.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E02.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E16.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E10.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: The.Sound.of.Music.1965.WEBRip.iTunes.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E01.HDTV.x264-AVS.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E07.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E02.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: C1 real level: B2 name: Frozen.2013.WEB-DL.DSNP.srt\n",
      "predicted: B2 real level: B2 name: The.True.Cost.2015.BluRay.720p.700MB.Ganool.com.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E09.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E08 - Pride & Joy.en.SDH.srt\n",
      "predicted: A2 real level: B2 name: The.Grinch.2018.REMUX.1080p.Blu-ray.AVC.TrueHD.DTS-HD.MA.7.1-LEGi0N.English.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E10.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E04.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B1 real level: B2 name: The.Notebook.DVDRip.XviD-DiAMOND.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E05.iNTERNAL.HDTV.x264-2HD.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 7- Hitting Home.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 15- Tick Tock.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 10- Faith.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E06 - Gelignite.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Suits.S01E08.1080p.BluRay.AAC5.1.x265-DTG.02.EN.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E05.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E03.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E11.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: C1 real level: B2 name: SOMM.Into.the.Bottle.2015.1080p.BluRay.x265-RARBG.en.srt.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E10.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E07 - Scientia Potentia Est.en.FORCED.srt\n",
      "predicted: B2 real level: B2 name: Virgin.River.S01E01.INTERNAL.720p.WEB.x264-STRiFE.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E03.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E06 - Gelignite.en.srt\n",
      "predicted: B2 real level: B2 name: Crazy4TV.com - Suits.S06E08.720p.BluRay.x265.HEVC.Crazy4ad.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E01 - Wolferton Splash.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E05 - Smoke and Mirrors.en.FORCED.srt\n",
      "predicted: C1 real level: B2 name: Crown, The S01E03 - Windsor.en.FORCED.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 2- Compensation.srt\n",
      "predicted: B2 real level: B2 name: Suits.S02E15.HDTV.x264-ASAP.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 9- Uninvited Guests.srt\n",
      "predicted: B2 real level: B2 name: Suits.Episode 6- Privilege.srt\n",
      "predicted: B2 real level: B2 name: Ghosts.of.Girlfriends.Past.2009.BluRay.720p.x264.YIFY.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E10 - Gloriana.en.SDH.srt\n",
      "predicted: B2 real level: B2 name: Crown, The S01E08 - Pride & Joy.en.srt\n",
      "predicted: A2 real level: A2 name: The Walking Dead-S01E03-Tell It To The Frogs.English.srt\n",
      "predicted: B2 real level: A2 name: The Walking Dead-S01E05-Wildfire.English.srt\n",
      "predicted: A2 real level: A2 name: The Walking Dead-S01E02-Guts.English.srt\n",
      "predicted: B2 real level: A2 name: The Walking Dead-S01E04-Vatos.English.srt\n",
      "predicted: A2 real level: A2 name: The Walking Dead-S01E06-TS-19.English.srt\n",
      "predicted: A2 real level: A2 name: The Walking Dead-S01E01-Days Gone Bye.English.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E11 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E01 - Episode 1.eng.SDH.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E08 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E02 - Episode 2.eng.SDH.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E03 - Episode 3.eng.SDH.srt\n",
      "predicted: C1 real level: C1 name: Suits S04E14 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E05 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E06.720p.HDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E02 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E13 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E04.480pHDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E16 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Suits.S03E10.HDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E07 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E05 - Episode 5.eng.SDH.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E09 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E04 - Episode 4.eng.SDH.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E07 - Episode 7.eng.SDH.srt\n",
      "predicted: C1 real level: C1 name: Suits S04E15 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Downton Abbey - S01E06 - Episode 6.eng.SDH.srt\n",
      "predicted: C1 real level: C1 name: Suits.S03E01.480pHDTV.x264-mSD.srt\n",
      "predicted: C1 real level: C1 name: Suits S04E04 EngSub.srt\n",
      "predicted: C1 real level: C1 name: Suits S04E01 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E09.480p.HDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E02.720pHDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E03.480pHDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E10 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E05.480p.HDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E08.480p.HDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E06 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits.S03E07.HDTV.x264-mSD.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E03 EngSub.srt\n",
      "predicted: B2 real level: C1 name: Suits S04E12 EngSub.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E06.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B2 real level: B1 name: Spirit.Stallion.of.the.Cimarron.EN.srt\n",
      "predicted: B1 real level: B1 name: AmericanBeauty1999.BRRip.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E01.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E07.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B1 real level: B1 name: Men.In.Black.1997.720p.Bluray.x264-SEPTiC.srt\n",
      "predicted: B1 real level: B1 name: Rat.Race.2001.1080p.WEB-DL.DD5.1.H264-FGT.srt\n",
      "predicted: B1 real level: B1 name: mechanic-resurrection_.srt\n",
      "predicted: B1 real level: B1 name: Valentine's.Day.2010.Subtitles.YIFY.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E02.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B2 real level: B1 name: SlingShot (2014) WEB.eng.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E05.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B2 real level: B1 name: Indiana Jones And The Last Crusade DVDRip Xvid -IZON-.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E04.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B1 real level: B1 name: Seven.Worlds.One.Planet.S01E03.2160p.BluRay.Remux.eng.srt\n",
      "predicted: B2 real level: B1 name: Angelas.Christmas.Wish.2020.srt\n",
      "predicted: B1 real level: B1 name: Terminator_2_Judgment_Day_1991_roNy.srt\n"
     ]
    }
   ],
   "source": [
    "for idx, movie in rows_res_df.iterrows():\n",
    "    print('predicted:', ppln.predict([movie['text']])[0], 'real level:', movie['level'], 'name:', movie['name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
